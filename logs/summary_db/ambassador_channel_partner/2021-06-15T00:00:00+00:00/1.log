[2021-06-16 12:57:39,571] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.ambassador_channel_partner 2021-06-15T00:00:00+00:00 [queued]>
[2021-06-16 12:57:39,927] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.ambassador_channel_partner 2021-06-15T00:00:00+00:00 [queued]>
[2021-06-16 12:57:39,928] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2021-06-16 12:57:39,928] {taskinstance.py:1068} INFO - Starting attempt 1 of 4
[2021-06-16 12:57:39,928] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2021-06-16 12:57:40,121] {taskinstance.py:1087} INFO - Executing <Task(PythonOperator): ambassador_channel_partner> on 2021-06-15T00:00:00+00:00
[2021-06-16 12:57:40,226] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'summary_db', 'ambassador_channel_partner', '2021-06-15T00:00:00+00:00', '--job-id', '176', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/first_dag.py', '--cfg-path', '/tmp/tmpiljv1re3', '--error-file', '/tmp/tmpy72aa9e3']
[2021-06-16 12:57:40,227] {standard_task_runner.py:77} INFO - Job 176: Subtask ambassador_channel_partner
[2021-06-16 12:57:40,235] {standard_task_runner.py:52} INFO - Started process 1063 to run task
[2021-06-16 12:58:14,693] {logging_mixin.py:104} INFO - Running <TaskInstance: summary_db.ambassador_channel_partner 2021-06-15T00:00:00+00:00 [running]> on host ac3e7c1eb084
[2021-06-16 12:59:00,493] {taskinstance.py:1282} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=summary_db
AIRFLOW_CTX_TASK_ID=ambassador_channel_partner
AIRFLOW_CTX_EXECUTION_DATE=2021-06-15T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-06-15T00:00:00+00:00
[2021-06-16 12:59:00,494] {logging_mixin.py:104} INFO - ------------------------------------Inside Function-----------------------------
[2021-06-16 12:59:09,373] {taskinstance.py:1481} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/MySQLdb/__init__.py", line 130, in Connect
    return Connection(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/MySQLdb/connections.py", line 185, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb._exceptions.OperationalError: (2003, "Can't connect to MySQL server on '3.0.136.197:3306' (111)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1137, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1311, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1341, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 150, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 161, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/first_dag.py", line 65, in ambassador_channel_partner
    con='mysql+mysqldb://'+REPLICA_DB_USER+':'+REPLICA_DB_PASSWORD+'@'+REPLICA_DB_HOST+':'+REPLICA_DB_PORT+'/'+REPLICA_DB+'?ssl_mode=DISABLED')
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 383, in read_sql_query
    chunksize=chunksize,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1295, in read_query
    result = self.execute(*args)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1162, in execute
    *args, **kwargs
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2234, in execute
    connection = self._contextual_connect(close_with_result=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/MySQLdb/__init__.py", line 130, in Connect
    return Connection(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/MySQLdb/connections.py", line 185, in __init__
    super().__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (MySQLdb._exceptions.OperationalError) (2003, "Can't connect to MySQL server on '3.0.136.197:3306' (111)")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2021-06-16 12:59:09,546] {taskinstance.py:1531} INFO - Marking task as UP_FOR_RETRY. dag_id=summary_db, task_id=ambassador_channel_partner, execution_date=20210615T000000, start_date=20210616T125739, end_date=20210616T125909
[2021-06-16 12:59:17,489] {local_task_job.py:151} INFO - Task exited with return code 1
[2021-06-16 13:02:44,749] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.ambassador_channel_partner 2021-06-15T00:00:00+00:00 [queued]>
[2021-06-16 13:02:46,516] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.ambassador_channel_partner 2021-06-15T00:00:00+00:00 [queued]>
[2021-06-16 13:02:46,517] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2021-06-16 13:02:46,517] {taskinstance.py:1068} INFO - Starting attempt 1 of 4
[2021-06-16 13:02:46,517] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2021-06-16 13:02:47,041] {taskinstance.py:1087} INFO - Executing <Task(PythonOperator): ambassador_channel_partner> on 2021-06-15T00:00:00+00:00
[2021-06-16 13:02:47,079] {standard_task_runner.py:52} INFO - Started process 1266 to run task
[2021-06-16 13:02:47,187] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'summary_db', 'ambassador_channel_partner', '2021-06-15T00:00:00+00:00', '--job-id', '189', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/first_dag.py', '--cfg-path', '/tmp/tmpaw9ewkcd', '--error-file', '/tmp/tmpz9x1lap0']
[2021-06-16 13:02:47,284] {standard_task_runner.py:77} INFO - Job 189: Subtask ambassador_channel_partner
[2021-06-16 13:02:59,446] {logging_mixin.py:104} INFO - Running <TaskInstance: summary_db.ambassador_channel_partner 2021-06-15T00:00:00+00:00 [running]> on host ac3e7c1eb084
[2021-06-16 13:03:21,623] {taskinstance.py:1282} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=summary_db
AIRFLOW_CTX_TASK_ID=ambassador_channel_partner
AIRFLOW_CTX_EXECUTION_DATE=2021-06-15T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-06-15T00:00:00+00:00
[2021-06-16 13:03:21,626] {logging_mixin.py:104} INFO - ------------------------------------Inside Function-----------------------------
[2021-06-16 13:03:43,030] {logging_mixin.py:104} INFO - -------------------------------Data read into dataframe---------------------------
[2021-06-16 13:04:03,940] {logging_mixin.py:104} INFO - ----------------------------------Data written into summary DB----------------------
[2021-06-16 13:04:03,940] {python.py:151} INFO - Done. Returned value was: None
[2021-06-16 13:04:04,281] {taskinstance.py:1191} INFO - Marking task as SUCCESS. dag_id=summary_db, task_id=ambassador_channel_partner, execution_date=20210615T000000, start_date=20210616T130244, end_date=20210616T130404
[2021-06-16 13:04:04,758] {taskinstance.py:1245} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2021-06-16 13:04:04,799] {local_task_job.py:151} INFO - Task exited with return code 0
