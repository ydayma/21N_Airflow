[2021-06-16 12:54:51,589] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.queue 2021-06-15T00:00:00+00:00 [queued]>
[2021-06-16 12:54:51,729] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.queue 2021-06-15T00:00:00+00:00 [queued]>
[2021-06-16 12:54:51,730] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2021-06-16 12:54:51,730] {taskinstance.py:1068} INFO - Starting attempt 1 of 4
[2021-06-16 12:54:51,731] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2021-06-16 12:54:51,806] {taskinstance.py:1087} INFO - Executing <Task(PythonOperator): queue> on 2021-06-15T00:00:00+00:00
[2021-06-16 12:54:51,853] {standard_task_runner.py:52} INFO - Started process 917 to run task
[2021-06-16 12:54:51,873] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'summary_db', 'queue', '2021-06-15T00:00:00+00:00', '--job-id', '167', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/first_dag.py', '--cfg-path', '/tmp/tmpc82yiolf', '--error-file', '/tmp/tmp_i89p1xt']
[2021-06-16 12:54:51,874] {standard_task_runner.py:77} INFO - Job 167: Subtask queue
[2021-06-16 12:54:52,093] {logging_mixin.py:104} INFO - Running <TaskInstance: summary_db.queue 2021-06-15T00:00:00+00:00 [running]> on host ac3e7c1eb084
[2021-06-16 12:54:52,434] {taskinstance.py:1282} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=summary_db
AIRFLOW_CTX_TASK_ID=queue
AIRFLOW_CTX_EXECUTION_DATE=2021-06-15T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-06-15T00:00:00+00:00
[2021-06-16 12:54:52,436] {logging_mixin.py:104} INFO - ------------------------------------Inside Function-----------------------------
[2021-06-16 12:54:57,113] {taskinstance.py:1481} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/MySQLdb/__init__.py", line 130, in Connect
    return Connection(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/MySQLdb/connections.py", line 185, in __init__
    super().__init__(*args, **kwargs2)
MySQLdb._exceptions.OperationalError: (2003, "Can't connect to MySQL server on '3.0.136.197:3306' (111)")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1137, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1311, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1341, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 150, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 161, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/first_dag.py", line 444, in queue
    con='mysql+mysqldb://'+REPLICA_DB_USER+':'+REPLICA_DB_PASSWORD+'@'+REPLICA_DB_HOST+':'+REPLICA_DB_PORT+'/'+REPLICA_DB+'?ssl_mode=DISABLED')
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 383, in read_sql_query
    chunksize=chunksize,
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1295, in read_query
    result = self.execute(*args)
  File "/home/airflow/.local/lib/python3.6/site-packages/pandas/io/sql.py", line 1162, in execute
    *args, **kwargs
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2234, in execute
    connection = self._contextual_connect(close_with_result=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.6/site-packages/MySQLdb/__init__.py", line 130, in Connect
    return Connection(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/MySQLdb/connections.py", line 185, in __init__
    super().__init__(*args, **kwargs2)
sqlalchemy.exc.OperationalError: (MySQLdb._exceptions.OperationalError) (2003, "Can't connect to MySQL server on '3.0.136.197:3306' (111)")
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2021-06-16 12:55:04,461] {taskinstance.py:1531} INFO - Marking task as UP_FOR_RETRY. dag_id=summary_db, task_id=queue, execution_date=20210615T000000, start_date=20210616T125451, end_date=20210616T125504
[2021-06-16 12:55:36,404] {local_task_job.py:151} INFO - Task exited with return code 1
[2021-06-16 13:03:00,440] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.queue 2021-06-15T00:00:00+00:00 [queued]>
[2021-06-16 13:03:12,095] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.queue 2021-06-15T00:00:00+00:00 [queued]>
[2021-06-16 13:03:12,096] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2021-06-16 13:03:12,096] {taskinstance.py:1068} INFO - Starting attempt 1 of 4
[2021-06-16 13:03:12,096] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2021-06-16 13:03:12,401] {taskinstance.py:1087} INFO - Executing <Task(PythonOperator): queue> on 2021-06-15T00:00:00+00:00
[2021-06-16 13:03:12,436] {standard_task_runner.py:52} INFO - Started process 1274 to run task
[2021-06-16 13:03:20,403] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'summary_db', 'queue', '2021-06-15T00:00:00+00:00', '--job-id', '196', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/first_dag.py', '--cfg-path', '/tmp/tmpju2ugp2p', '--error-file', '/tmp/tmpp3pvmcmz']
[2021-06-16 13:03:20,404] {standard_task_runner.py:77} INFO - Job 196: Subtask queue
[2021-06-16 13:03:24,053] {logging_mixin.py:104} INFO - Running <TaskInstance: summary_db.queue 2021-06-15T00:00:00+00:00 [running]> on host ac3e7c1eb084
[2021-06-16 13:03:44,019] {taskinstance.py:1282} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=summary_db
AIRFLOW_CTX_TASK_ID=queue
AIRFLOW_CTX_EXECUTION_DATE=2021-06-15T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-06-15T00:00:00+00:00
[2021-06-16 13:03:44,020] {logging_mixin.py:104} INFO - ------------------------------------Inside Function-----------------------------
[2021-06-16 13:05:34,975] {logging_mixin.py:104} INFO - -------------------------------Data read into dataframe---------------------------
[2021-06-16 13:05:37,324] {logging_mixin.py:104} INFO - ----------------------------------Data written into summary DB----------------------
[2021-06-16 13:05:37,324] {python.py:151} INFO - Done. Returned value was: None
[2021-06-16 13:05:37,348] {taskinstance.py:1191} INFO - Marking task as SUCCESS. dag_id=summary_db, task_id=queue, execution_date=20210615T000000, start_date=20210616T130300, end_date=20210616T130537
[2021-06-16 13:05:37,474] {taskinstance.py:1245} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2021-06-16 13:05:37,587] {local_task_job.py:151} INFO - Task exited with return code 0
