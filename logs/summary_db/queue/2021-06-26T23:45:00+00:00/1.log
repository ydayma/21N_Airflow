[2021-06-28 15:20:22,153] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.queue 2021-06-26T23:45:00+00:00 [queued]>
[2021-06-28 15:20:22,377] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.queue 2021-06-26T23:45:00+00:00 [queued]>
[2021-06-28 15:20:22,378] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2021-06-28 15:20:22,379] {taskinstance.py:1068} INFO - Starting attempt 1 of 4
[2021-06-28 15:20:22,380] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2021-06-28 15:20:22,475] {taskinstance.py:1087} INFO - Executing <Task(PythonOperator): queue> on 2021-06-26T23:45:00+00:00
[2021-06-28 15:20:22,498] {standard_task_runner.py:52} INFO - Started process 338 to run task
[2021-06-28 15:20:22,516] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'summary_db', 'queue', '2021-06-26T23:45:00+00:00', '--job-id', '290', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/analytics_summary.py', '--cfg-path', '/tmp/tmp5akofpss', '--error-file', '/tmp/tmpg6q2kq2b']
[2021-06-28 15:20:22,517] {standard_task_runner.py:77} INFO - Job 290: Subtask queue
[2021-06-28 15:20:22,967] {logging_mixin.py:104} INFO - Running <TaskInstance: summary_db.queue 2021-06-26T23:45:00+00:00 [running]> on host 32c9461fc328
[2021-06-28 15:20:23,277] {taskinstance.py:1282} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=summary_db
AIRFLOW_CTX_TASK_ID=queue
AIRFLOW_CTX_EXECUTION_DATE=2021-06-26T23:45:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-06-26T23:45:00+00:00
[2021-06-28 15:20:23,280] {logging_mixin.py:104} INFO - ------------------------------------Inside Function-----------------------------
[2021-06-28 15:24:02,412] {logging_mixin.py:104} INFO - -------------------------------Data read into dataframe---------------------------
[2021-06-28 15:24:04,208] {logging_mixin.py:104} INFO - ----------------------------------Data written into summary DB----------------------
[2021-06-28 15:24:04,208] {python.py:151} INFO - Done. Returned value was: None
[2021-06-28 15:24:04,231] {taskinstance.py:1191} INFO - Marking task as SUCCESS. dag_id=summary_db, task_id=queue, execution_date=20210626T234500, start_date=20210628T152022, end_date=20210628T152404
[2021-06-28 15:24:04,301] {taskinstance.py:1245} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2021-06-28 15:24:04,335] {local_task_job.py:151} INFO - Task exited with return code 0
[2021-06-28 15:39:47,585] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.queue 2021-06-26T23:45:00+00:00 [queued]>
[2021-06-28 15:39:47,661] {taskinstance.py:876} INFO - Dependencies all met for <TaskInstance: summary_db.queue 2021-06-26T23:45:00+00:00 [queued]>
[2021-06-28 15:39:47,681] {taskinstance.py:1067} INFO - 
--------------------------------------------------------------------------------
[2021-06-28 15:39:47,681] {taskinstance.py:1068} INFO - Starting attempt 1 of 4
[2021-06-28 15:39:47,681] {taskinstance.py:1069} INFO - 
--------------------------------------------------------------------------------
[2021-06-28 15:39:47,713] {taskinstance.py:1087} INFO - Executing <Task(PythonOperator): queue> on 2021-06-26T23:45:00+00:00
[2021-06-28 15:39:47,739] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'summary_db', 'queue', '2021-06-26T23:45:00+00:00', '--job-id', '318', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/analytics_summary.py', '--cfg-path', '/tmp/tmputfhhjt7', '--error-file', '/tmp/tmp38o6ojc1']
[2021-06-28 15:39:47,740] {standard_task_runner.py:77} INFO - Job 318: Subtask queue
[2021-06-28 15:39:47,732] {standard_task_runner.py:52} INFO - Started process 417 to run task
[2021-06-28 15:39:47,870] {logging_mixin.py:104} INFO - Running <TaskInstance: summary_db.queue 2021-06-26T23:45:00+00:00 [running]> on host 32c9461fc328
[2021-06-28 15:39:48,069] {taskinstance.py:1282} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=summary_db
AIRFLOW_CTX_TASK_ID=queue
AIRFLOW_CTX_EXECUTION_DATE=2021-06-26T23:45:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-06-26T23:45:00+00:00
[2021-06-28 15:39:48,076] {logging_mixin.py:104} INFO - ------------------------------------Inside Function-----------------------------
[2021-06-28 15:41:33,292] {logging_mixin.py:104} INFO - -------------------------------Data read into dataframe---------------------------
[2021-06-28 15:41:35,059] {logging_mixin.py:104} INFO - ----------------------------------Data written into summary DB----------------------
[2021-06-28 15:41:35,059] {python.py:151} INFO - Done. Returned value was: None
[2021-06-28 15:41:35,073] {taskinstance.py:1191} INFO - Marking task as SUCCESS. dag_id=summary_db, task_id=queue, execution_date=20210626T234500, start_date=20210628T153947, end_date=20210628T154135
[2021-06-28 15:41:35,119] {taskinstance.py:1245} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2021-06-28 15:41:35,164] {local_task_job.py:151} INFO - Task exited with return code 0
